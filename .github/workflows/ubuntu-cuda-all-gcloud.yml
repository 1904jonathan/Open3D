name: Ubuntu CUDA GCloud CI

on:
  workflow_dispatch:
  push:
    branches:
      - master
  pull_request:
    types: [opened, reopened, synchronize]

jobs:
  build-container:
    name: Build container
    runs-on: ubuntu-20.04
    strategy:
      fail-fast: false
    env:
      DEVELOPER_BUILD: ON
      PYTHON_VERSION: 3.6
    steps:
      # - name: Cancel outdated
      #   uses: fkirc/skip-duplicate-actions@master
      #   with:
      #     github_token: ${{ github.token }}
      - name: Checkout source code
        uses: actions/checkout@v2
      - name: Package code
        run: |
          # GITHUB_WORKSPACE: /home/runner/work/Open3D/Open3D
          cd ${GITHUB_WORKSPACE}/..
          tar -czvf Open3D.tar.gz Open3D
          ls -alh
      - name: Set global DOCKER_TAG and VM_NAME
        run: |
          GIT_HASH=$(git rev-parse --short HEAD)
          DOCKER_TAG=open3d-ubuntu-cuda-gcloud-ci:2-bionic-${GIT_HASH}
          VM_NAME=open3d-ubuntu-cuda-gcloud-ci-2-bionic-${GIT_HASH}
          echo "GIT_HASH=${GIT_HASH}"     >> $GITHUB_ENV
          echo "DOCKER_TAG=${DOCKER_TAG}" >> $GITHUB_ENV
          echo "VM_NAME=${VM_NAME}"       >> $GITHUB_ENV
      - name: GCloud CLI setup
        uses: google-github-actions/setup-gcloud@master
        with:
          version: ${{ env.GCE_CLI_GHA_VERSION }}
          service_account_key: ${{ secrets.GCE_SA_KEY_GPU_CI }}
          project_id: ${{ secrets.GCE_PROJECT }}
      - name: VM create
        run: |
          GCE_ZONES=(us-west1-a us-west1-b us-central1-a us-central1-b
                     us-central1-f us-east1-c us-east1-d us-east4-b
                     southamerica-east1-c europe-west2-b europe-west3-b
                     europe-west4-b europe-west4-c europe-west2-a
                     asia-southeast1-b asia-southeast1-c australia-southeast1-a)
          GCE_ZID=0
          until ((GCE_ZID >= ${#GCE_ZONES[@]})) ||
            gcloud compute instances create ${{ env.VM_NAME }} \
              --project=${{ secrets.GCE_PROJECT }} \
              --zone="${GCE_ZONES[$GCE_ZID]}" \
              --service-account="${{ secrets.GCE_GPU_CI_SA }}" \
              --image-family common-cu110 \
              --image-project deeplearning-platform-release \
              --accelerator="count=2,type=nvidia-tesla-t4" \
              --maintenance-policy=TERMINATE \
              --machine-type=n1-standard-4 \
              --boot-disk-size=120GB \
              --boot-disk-type=pd-ssd \
              --scopes https://www.googleapis.com/auth/devstorage.full_control \
              --metadata="install-nvidia-driver=True,proxy-mode=project_editors"; do
            ((GCE_ZID = GCE_ZID + 1))
          done
          VM_ZONE="${GCE_ZONES[$GCE_ZID]}"
          echo "VM created successfully in VM_ZONE=${VM_ZONE}"
          echo "VM_ZONE=${VM_ZONE}" >> "$GITHUB_ENV"
          sleep 90s # Wait for nvidia driver installation
          exit $((GCE_ZID >= ${#GCE_ZONES[@]})) # 0 => success
      - name: VM copy code
        run: |
          # https://github.com/kyma-project/test-infra/issues/93#issuecomment-457263589
          for i in $(gcloud compute os-login ssh-keys list | grep -v FINGERPRINT); do \
              echo "Removing ssh key"; \
              gcloud compute os-login ssh-keys remove --key $i || true; \
          done
          gcloud compute scp ${GITHUB_WORKSPACE}/../Open3D.tar.gz ${{ env.VM_NAME }}:~ \
            --zone=${{ env.VM_ZONE }}
          gcloud compute ssh ${{ env.VM_NAME }} \
            --zone=${{ env.VM_ZONE }} \
            --command "ls -alh \
                    && tar -xvzf Open3D.tar.gz \
                    && ls -alh \
                    && ls -alh Open3D"
      - name: VM Docker build
        run: |
          gcloud compute ssh ${{ env.VM_NAME }} \
            --zone=${{ env.VM_ZONE }} \
            --command "sudo Open3D/.github/workflows/docker_build.sh 2-bionic"
          echo "Docker DOCKER_TAG=${{ env.DOCKER_TAG }} is built."
          echo "CCache tar CCACHE_TAR_NAME=${{ env.CCACHE_TAR_NAME }} is generated."
      - name: VM Docker run
        run: |
          gcloud compute ssh ${{ env.VM_NAME }} \
            --zone=${{ env.VM_ZONE }} \
            --command "sudo docker run -i --rm --gpus all ${{ env.DOCKER_TAG }} nvidia-smi"
      # - name: Docker save
      #   run: |
      #     docker image ls
      #     df -h
      #     docker save ${{ env.DOCKER_TAG }} | gzip > ${{ env.DOCKER_TAR }}
      #     df -h
      # - name: CCache upload
      #   run: |
      #     # if: ${{ github.ref == 'refs/heads/master' }}
      #     echo "CCache tar name: ${{ env.CCACHE_TAR_NAME }}"
      #     ls -alh
      #     gsutil cp ${GITHUB_WORKSPACE}/${{ env.CCACHE_TAR_NAME }}.tar.gz gs://open3d-ci-cache/
      # - name: Docker upload
      #   run: |
      #     gsutil cp ${{ env.DOCKER_TAR }} gs://open3d-docker/
      # - name: VM create
      #   run: |
      #     GCE_ZONES=(us-west1-a us-west1-b us-central1-a us-central1-b
      #                us-central1-f us-east1-c us-east1-d us-east4-b
      #                southamerica-east1-c europe-west2-b europe-west3-b
      #                europe-west4-b europe-west4-c europe-west2-a
      #                asia-southeast1-b asia-southeast1-c australia-southeast1-a)
      #     GCE_ZID=0
      #     until ((GCE_ZID >= ${#GCE_ZONES[@]})) ||
      #       gcloud compute instances create ${{ env.VM_NAME }} \
      #         --project=${{ secrets.GCE_PROJECT }} \
      #         --zone="${GCE_ZONES[$GCE_ZID]}" \
      #         --service-account="${{ secrets.GCE_GPU_CI_SA }}" \
      #         --image-family common-cu110 \
      #         --image-project deeplearning-platform-release \
      #         --accelerator="count=2,type=nvidia-tesla-t4" \
      #         --maintenance-policy=TERMINATE \
      #         --machine-type=n1-standard-4 \
      #         --boot-disk-size=120GB \
      #         --boot-disk-type=pd-ssd \
      #         --scopes https://www.googleapis.com/auth/devstorage.full_control \
      #         --metadata="install-nvidia-driver=True,proxy-mode=project_editors"; do
      #       ((GCE_ZID = GCE_ZID + 1))
      #     done
      #     VM_ZONE="${GCE_ZONES[$GCE_ZID]}"
      #     echo "VM created successfully in VM_ZONE=${VM_ZONE}"
      #     echo "VM_ZONE=${VM_ZONE}" >> "$GITHUB_ENV"
      #     sleep 90s # Wait for nvidia driver installation
      #     exit $((GCE_ZID >= ${#GCE_ZONES[@]})) # 0 => success
      # - name: VM Docker download
      #   run: |
      #     # https://github.com/kyma-project/test-infra/issues/93#issuecomment-457263589
      #     for i in $(gcloud compute os-login ssh-keys list | grep -v FINGERPRINT); do \
      #         echo "Removing ssh key"; \
      #         gcloud compute os-login ssh-keys remove --key $i || true; \
      #     done
      #     gcloud compute ssh ${{ env.VM_NAME }} \
      #       --zone=${{ env.VM_ZONE }} \
      #       --command "df -h"
      #     gcloud compute ssh ${{ env.VM_NAME }} \
      #       --zone=${{ env.VM_ZONE }} \
      #       --command "sudo gcloud auth configure-docker \
      #               && gsutil cp gs://open3d-docker/${{ env.DOCKER_TAR }} ${{ env.DOCKER_TAR }} \
      #               && sudo docker load --input ${{ env.DOCKER_TAR }}"
      #     gcloud compute ssh ${{ env.VM_NAME }} \
      #       --zone=${{ env.VM_ZONE }} \
      #       --command "df -h"
      # - name: VM Docker run
      #   run: |
      #     gcloud compute ssh ${{ env.VM_NAME }} \
      #       --zone=${{ env.VM_ZONE }} \
      #       --command "df -h"
      #     gcloud compute ssh ${{ env.VM_NAME }} \
      #       --zone=${{ env.VM_ZONE }} \
      #       --command "sudo docker run -i --rm --gpus all ${{ env.DOCKER_TAG }} nvidia-smi"
      #     gcloud compute ssh ${{ env.VM_NAME }} \
      #       --zone=${{ env.VM_ZONE }} \
      #       --command "df -h"
      - name: VM delete
        if: always()
        run: |
          gcloud compute instances delete ${{ env.VM_NAME }} \
            --zone=${{ env.VM_ZONE }} \
            --quiet
      # - name: Docker delete
      #   if: always()
      #   run: |
      #     gsutil rm gs://open3d-docker/${{ env.DOCKER_TAR }}
