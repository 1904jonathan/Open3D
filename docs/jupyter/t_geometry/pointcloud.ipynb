{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using external Open3D-ML in /root/Open3D-ML\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import open3d.core as o3c\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointCloud\n",
    "This tutorial demonstrates basic usage of a point cloud.\n",
    "\n",
    "## PointCloud creation\n",
    "The first part of the tutorial shows how to construct a point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a empty point cloud on CPU.\n",
    "pcd = o3d.t.geometry.PointCloud()\n",
    "print(pcd)\n",
    "# Create a empty point cloud on GPU.\n",
    "pcd = o3d.t.geometry.PointCloud(o3c.Device(\"CUDA:0\"))\n",
    "print(pcd)\n",
    "\n",
    "# Create a point cloud from open3d tensor.\n",
    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32))\n",
    "print(pcd)\n",
    "# Create a point cloud from open3d tensor with float64.\n",
    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float64))\n",
    "print(pcd)\n",
    "# Create a point cloud from open3d tensor on GPU.\n",
    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32, o3c.Device(\"CUDA:0\")))\n",
    "print(pcd)\n",
    "\n",
    "# Special creation.\n",
    "# Create a point cloud from numpy array.\n",
    "pcd = o3d.t.geometry.PointCloud(np.array([[0, 0, 0], [1, 1, 1]], dtype=np.float32))\n",
    "print(pcd)\n",
    "# Create a point cloud from python list.\n",
    "pcd = o3d.t.geometry.PointCloud([[0., 0., 0.], [1., 1., 1.]])\n",
    "print(pcd)\n",
    "\n",
    "# Error creation. The point cloud must have shape of (N, 3).\n",
    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([0, 0, 0, 0], o3c.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PointCloud` can be created on both CPU and GPU, and with different data types. The device of the point cloud will be the same as the device of the input tensor.\n",
    "\n",
    "Besides, `PointCloud` can be also created by python dict with multiple attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_tensors = {}\n",
    "# The `positions` attribute must be specified.\n",
    "map_to_tensors['positions'] = o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32)\n",
    "map_to_tensors['normals'] = o3c.Tensor([[0, 0, 1], [0, 0, 1]], o3c.float32)\n",
    "map_to_tensors['labels'] = o3c.Tensor([0, 1], o3c.int64)\n",
    "\n",
    "pcd = o3d.t.geometry.PointCloud(map_to_tensors)\n",
    "print(pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointCloud attributes setter and getter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32))\n",
    "# Set attributes.\n",
    "pcd.point.normals = o3c.Tensor([[0, 0, 1], [0, 0, 1]], o3c.float32)\n",
    "pcd.point.colors = o3c.Tensor([[1, 0, 0], [0, 1, 0]], o3c.float32)\n",
    "pcd.point.labels = o3c.Tensor([0, 1], o3c.int64)\n",
    "print(pcd, '\\n')\n",
    "\n",
    "# Set by numpy array or python list.\n",
    "pcd.point.normals = np.array([[0, 0, 1], [0, 0, 1]], dtype=np.float32)\n",
    "pcd.point.intensity = [0.4, 0.4]\n",
    "print(pcd, '\\n')\n",
    "\n",
    "# Get attributes.\n",
    "posisions = pcd.point.positions\n",
    "print('posisions: ')\n",
    "print(posisions, '\\n')\n",
    "labels = pcd.point.labels\n",
    "print('labels: ')\n",
    "print(labels, '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a ply point cloud, print it, and render it\n",
      "PointCloud on CPU:0 [196133 points (Float32)].\n",
      "Attributes: curvature (dtype = Float32, shape = {196133, 1}), normals (dtype = Float32, shape = {196133, 3}), colors (dtype = UInt8, shape = {196133, 3}).\n"
     ]
    }
   ],
   "source": [
    "print(\"Load a ply point cloud, print it, and render it\")\n",
    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "pcd = o3d.t.io.read_point_cloud(ply_point_cloud.path)\n",
    "print(pcd)\n",
    "# TODO: (use `draw` instead?)\n",
    "o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_point_cloud` reads a point cloud from a file. It tries to decode the file based on the extension name. For a list of supported file types, refer to [File IO](file_io.ipynb) (this should be `t::io`).\n",
    "\n",
    "`draw_geometries` visualizes the point cloud. Use a mouse/trackpad to see the geometry from different view points.\n",
    "\n",
    "It looks like a dense surface, but it is actually a point cloud rendered as surfels. The GUI supports various keyboard functions. For instance, the `-` key reduces the size of the points (surfels).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Note:** \n",
    "\n",
    "Press the `H` key to print out a complete list of keyboard instructions for the GUI. For more information of the visualization GUI, refer to [Visualization](visualization.ipynb) and [Customized visualization](../visualization/customized_visualization.rst).\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Note:** \n",
    "\n",
    "On macOS, the GUI window may not receive keyboard events. In this case, try to launch Python with `pythonw` instead of `python`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling\n",
    "This section provides several downsamle methods of a point cloud.\n",
    "### Voxel downsampling\n",
    "Voxel downsampling uses a regular voxel grid to create a uniformly downsampled point cloud from an input point cloud. It is often used as a pre-processing step for many point cloud processing tasks. The algorithm operates in two steps:\n",
    "\n",
    "1. Points are bucketed into voxels.\n",
    "2. Each occupied voxel generates exactly one point by averaging all points inside. \n",
    "\n",
    "TODO: Currently, the method return the voxel coordinates of the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample the point cloud with a voxel of 0.03\n"
     ]
    }
   ],
   "source": [
    "print(\"Downsample the point cloud with a voxel of 0.03\")\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.03)\n",
    "o3d.visualization.draw_geometries([downpcd.to_legacy()],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farthest point downsampling\n",
    "Farthest point sampling sample the point cloud by selecting the farthest point from the current selected point cloud iteratively. It is use to sample the point cloud to a fixed number of points which holds the maximum geometrical information of the original point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample the point cloud by selecting 5000 farthest points.\n"
     ]
    }
   ],
   "source": [
    "print(\"Downsample the point cloud by selecting 5000 farthest points.\")\n",
    "downpcd_farthest = pcd.farthest_point_down_sample(5000)\n",
    "o3d.visualization.draw_geometries([downpcd_farthest.to_legacy()],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open3D also provides `uniform_down_sample` and `random_down_sample` for point cloud downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex normal estimation\n",
    "Another basic operation for point cloud is normal estimation.\n",
    "Press `N` to see point normals. The keys `-` and `+` can be used to control the length of the normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompute the normal of the downsampled point cloud using hybrid nearest neighbor search with 30 max_nn and radius of 0.1m.\n"
     ]
    }
   ],
   "source": [
    "print(\"Recompute the normal of the downsampled point cloud using hybrid nearest neighbor search with 30 max_nn and radius of 0.1m.\")\n",
    "downpcd.estimate_normals(max_nn=30, radius=0.1)\n",
    "o3d.visualization.draw_geometries([downpcd.to_legacy()],\n",
    "                                  zoom=0.3412,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[2.6172, 2.0475, 1.532],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024],\n",
    "                                  point_show_normal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`estimate_normals` computes the normal for every point. The function finds adjacent points and calculates the principal axis of the adjacent points using covariance analysis.\n",
    "\n",
    "The two key arguments `radius = 0.1` and `max_nn = 30` specifies search radius and maximum nearest neighbor. It has 10cm of search radius, and only considers up to 30 neighbors to save computation time. If only `max_nn` or `radius` is specified, the function will use knn or radius search respectively. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Note:** \n",
    "It is always recommended to specify both `radius` and `max_nn`, especially if the point cloud is on CUDA device.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Note:** \n",
    "The covariance analysis algorithm produces two opposite directions as normal candidates. Without knowing the global structure of the geometry, both can be correct. This is known as the normal orientation problem. Open3D tries to orient the normal to align with the original normal if it exists. Otherwise, Open3D does a random guess. Further orientation functions such as `orient_normals_to_align_with_direction` and `orient_normals_towards_camera_location` need to be called if the orientation is a concern.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access estimated normals\n",
    "The estimated normals can be access and converted to numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print first 5 normals of the downsampled point cloud.\n",
      "[[-0.501699 0.126191 -0.855789],\n",
      " [-0.428905 0.104427 -0.897293],\n",
      " [-0.396863 0.0474221 -0.916652],\n",
      " [-0.488195 0.102253 -0.866724],\n",
      " [-0.408576 0.240975 -0.880339]]\n",
      "Tensor[shape={5, 3}, stride={3, 1}, Float32, CPU:0, 0x55be45cf3e40] \n",
      "\n",
      "Convert normals tensor into numpy array.\n",
      "[[-0.5016988   0.12619077 -0.85578865]\n",
      " [-0.42890513  0.10442688 -0.8972932 ]\n",
      " [-0.39686304  0.04742212 -0.916652  ]\n",
      " [-0.48819506  0.10225325 -0.86672354]\n",
      " [-0.40857556  0.24097526 -0.880339  ]]\n"
     ]
    }
   ],
   "source": [
    "normals = downpcd.point.normals\n",
    "print('Print first 5 normals of the downsampled point cloud.')\n",
    "print(normals[:5], '\\n')\n",
    "print('Convert normals tensor into numpy array.')\n",
    "normals_np = normals.numpy()\n",
    "print(normals_np[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load a polygon volume and use it to crop the original point cloud\n"
     ]
    }
   ],
   "source": [
    "print(\"Load a polygon volume and use it to crop the original point cloud\")\n",
    "demo_crop_data = o3d.data.DemoCropPointCloud()\n",
    "pcd = o3d.t.io.read_point_cloud(demo_crop_data.point_cloud_path)\n",
    "vol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)\n",
    "chair = vol.crop_point_cloud(pcd.to_legacy())\n",
    "o3d.visualization.draw_geometries([chair],\n",
    "                                  zoom=0.7,\n",
    "                                  front=[0.5439, -0.2333, -0.8060],\n",
    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
    "                                  up=[-0.1781, -0.9708, 0.1608])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_selection_polygon_volume` reads a json file that specifies polygon selection area. `vol.crop_point_cloud(pcd)` filters out points. Only the chair remains.\n",
    "\n",
    "We can also get the cropped indices of the point cloud using `crop_in_polygon`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped indices length: 31337\n"
     ]
    }
   ],
   "source": [
    "indices = vol.crop_in_polygon(pcd.to_legacy())\n",
    "print(f'Cropped indices length: {len(indices)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paint point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paint point cloud.\n"
     ]
    }
   ],
   "source": [
    "print(\"Paint point cloud.\")\n",
    "pcd = pcd.paint_uniform_color([1, 0.706, 0])\n",
    "o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
    "                                  zoom=0.7,\n",
    "                                  front=[0.5439, -0.2333, -0.8060],\n",
    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
    "                                  up=[-0.1781, -0.9708, 0.1608])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`paint_uniform_color` paints all the points to a uniform color. The color is in RGB space, [0, 1] range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding volumes\n",
    "The `PointCloud` geometry type has bounding volumes as all other geometry types in Open3D. Currently, Open3D implements an `AxisAlignedBoundingBox` and an `OrientedBoundingBox` that can also be used to crop the geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "aabb = pcd.get_axis_aligned_bounding_box()\n",
    "aabb.set_color(o3c.Tensor([1, 0, 0], o3c.float32))\n",
    "# obb = pcd.get_oriented_bounding_box()\n",
    "# obb.color = (0, 1, 0)\n",
    "o3d.visualization.draw_geometries([pcd.to_legacy(), aabb.to_legacy()],\n",
    "                                  zoom=0.7,\n",
    "                                  front=[0.5439, -0.2333, -0.8060],\n",
    "                                  lookat=[2.4615, 2.1331, 1.338],\n",
    "                                  up=[-0.1781, -0.9708, 0.1608])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex hull\n",
    "The convex hull of a point cloud is the smallest convex set that contains all points. Open3D contains the method `compute_convex_hull` that computes the convex hull of a point cloud. The implementation is based on [Qhull](http://www.qhull.org/).\n",
    "\n",
    "In the example code below we compute the convex hull that is returned as a triangle mesh. Then, we visualize the convex hull as a red `LineSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bunny = o3d.data.BunnyMesh()\n",
    "pcd = o3d.t.io.read_point_cloud(bunny.path)\n",
    "\n",
    "hull = pcd.compute_convex_hull()\n",
    "hull_ls = o3d.geometry.LineSet.create_from_triangle_mesh(hull.to_legacy())\n",
    "hull_ls.paint_uniform_color((1, 0, 0))\n",
    "o3d.visualization.draw_geometries([pcd.to_legacy(), hull_ls])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN clustering\n",
    "Given a point cloud from e.g. a depth sensor we want to group local point cloud clusters together. For this purpose, we can use clustering algorithms. Open3D implements DBSCAN [\\[Ester1996\\]](../reference.html#Ester1996) that is a density based clustering algorithm. The algorithm is implemented in `cluster_dbscan` and requires two parameters: `eps` defines the distance to neighbors in a cluster and `min_points` defines the minimum number of points required to form a cluster. The function returns `labels`, where the label `-1` indicates noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D DEBUG] Precompute neighbors.\n",
      "[Open3D DEBUG] Done Precompute neighbors.\n",
      "[Open3D DEBUG] Compute Clusters\n",
      "Precompute neighbors.[========================================] 100%\n",
      "[Open3D DEBUG] Done Compute Clusters: 10==========>] 97%\n",
      "point cloud has 10 clusters\n"
     ]
    }
   ],
   "source": [
    "ply_point_cloud = o3d.data.PLYPointCloud()\n",
    "pcd = o3d.t.io.read_point_cloud(ply_point_cloud.path)\n",
    "\n",
    "with o3d.utility.VerbosityContextManager(\n",
    "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
    "    labels = pcd.cluster_dbscan(eps=0.02, min_points=10, print_progress=True)\n",
    "\n",
    "max_label = labels.max().item()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "colors = plt.get_cmap(\"tab20\")(\n",
    "        labels.numpy() / (max_label if max_label > 0 else 1))\n",
    "colors = o3c.Tensor(colors[:, :3], o3c.float32)\n",
    "colors[labels < 0] = 0\n",
    "pcd.point.colors = colors\n",
    "o3d.visualization.draw_geometries([pcd.to_legacy()],\n",
    "                                  zoom=0.455,\n",
    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
    "                                  up=[0.1204, -0.9852, 0.1215])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Note:** \n",
    "\n",
    "This algorithm precomputes all neighbors in the epsilon radius for all points. This can require a lot of memory if the chosen epsilon is too large.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plane segmentation\n",
    "Open3D also supports segmententation of geometric primitives from point clouds using RANSAC. To find the plane with the largest support in the point cloud, we can use `segment_plane`. The method has four arguments: `distance_threshold` defines the maximum distance a point can have to an estimated plane to be considered an inlier, `ransac_n` defines the number of points that are randomly sampled to estimate a plane, `num_iterations` defines how often a random plane is sampled and verified, and `probability` defined the expected probability of finding the optimal plane. The function then returns the plane as $(a,b,c,d)$ such that for each point $(x,y,z)$ on the plane we have $ax + by + cz + d = 0$. The function further returns a indices of the inlier points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane equation: -0.05x + -0.10y + 0.99z + -1.08 = 0\n"
     ]
    }
   ],
   "source": [
    "sample_pcd_data = o3d.data.PCDPointCloud()\n",
    "pcd = o3d.t.io.read_point_cloud(sample_pcd_data.path)\n",
    "plane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n",
    "                                            ransac_n=3,\n",
    "                                            num_iterations=1000)\n",
    "[a, b, c, d] = plane_model.numpy().tolist()\n",
    "print(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n",
    "\n",
    "inlier_cloud = pcd.select_by_index(inliers)\n",
    "inlier_cloud = inlier_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([inlier_cloud.to_legacy(), outlier_cloud.to_legacy()],\n",
    "                                  zoom=0.8,\n",
    "                                  front=[-0.4999, -0.1659, -0.8499],\n",
    "                                  lookat=[2.1813, 2.0619, 2.0999],\n",
    "                                  up=[0.1204, -0.9852, 0.1215])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden point removal\n",
    "Imagine you want to render a point cloud from a given view point, but points from the background leak into the foreground because they are not occluded by other points. For this purpose we can apply a hidden point removal algorithm. In Open3D the method by [\\[Katz2007\\]](../reference.html#Katz2007) is implemented that approximates the visibility of a point cloud from a given view without surface reconstruction or normal estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Convert mesh to a point cloud and estimate dimensions\")\n",
    "armadillo = o3d.data.ArmadilloMesh()\n",
    "mesh = o3d.io.read_triangle_mesh(armadillo.path)\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "pcd = mesh.sample_points_poisson_disk(5000)\n",
    "diameter = np.linalg.norm(\n",
    "    np.asarray(pcd.get_max_bound()) - np.asarray(pcd.get_min_bound()))\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "print(\"Define parameters used for hidden_point_removal\")\n",
    "camera = [0, 0, diameter]\n",
    "radius = diameter * 100\n",
    "\n",
    "print(\"Get all points that are visible from given view point\")\n",
    "_, pt_map = pcd.hidden_point_removal(camera, radius)\n",
    "\n",
    "print(\"Visualize result\")\n",
    "pcd = pcd.select_by_index(pt_map)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('open3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3ff712f491db3b4ccd20005f84e312b261650c105d83adbc3f83f5ecf60b94b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
